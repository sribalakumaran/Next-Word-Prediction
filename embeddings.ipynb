{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNd9etSboRnoL/XLcauuImA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gSznYCqjWG6","executionInfo":{"status":"ok","timestamp":1744856934948,"user_tz":-330,"elapsed":1175,"user":{"displayName":"21PW36 - SRIBALAKUMARAN S","userId":"00527892797507809189"}},"outputId":"b7f95d9b-501f-43a9-86fd-0e07bd7a84c4"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Sentence embeddings shape: torch.Size([3, 768])\n","The quick brown fox jumps over the lazy dog\n","Embedding: tensor([ 0.0475,  0.1346, -0.4781,  0.1008,  0.0408])...\n","A cat sits on the mat\n","Embedding: tensor([-0.4104,  0.0799, -0.7947,  0.2987, -0.1682])...\n","Sunny hills bloom with vivid colors\n","Embedding: tensor([-0.1217, -0.0164, -1.2168,  0.1202,  0.0949])...\n","The quick brown fox jumps over the lazy dog\n","Words: ['the', 'quick', 'brown', 'fox', 'j', 'umps', 'over', 'the', 'l', 'azy', 'dog']\n","Word embeddings shape: torch.Size([11, 768])\n","Word: the, Embedding[:5]: tensor([-0.1116, -0.0376, -0.2625,  0.0089, -0.0062])\n","Word: quick, Embedding[:5]: tensor([ 0.0089, -0.0820, -0.5968, -0.0222, -0.0429])\n","Word: brown, Embedding[:5]: tensor([-0.0561,  0.0763, -0.4878, -0.1101, -0.0216])\n","Word: fox, Embedding[:5]: tensor([-0.2120, -0.0151, -0.3472, -0.0302,  0.0186])\n","Word: j, Embedding[:5]: tensor([-0.0441, -0.1131, -0.3866,  0.0148,  0.0388])\n","Word: umps, Embedding[:5]: tensor([-0.2245, -0.0068, -0.3665,  0.0061, -0.0343])\n","Word: over, Embedding[:5]: tensor([-1.3074e-01,  3.0139e-02, -4.4021e-01,  8.4237e-02,  5.1440e-05])\n","Word: the, Embedding[:5]: tensor([-0.1116, -0.0376, -0.2625,  0.0089, -0.0062])\n","Word: l, Embedding[:5]: tensor([-0.0967, -0.0303, -0.3699,  0.0138,  0.0354])\n","Word: azy, Embedding[:5]: tensor([-0.0259, -0.0816, -0.2364, -0.1649,  0.0223])\n","Word: dog, Embedding[:5]: tensor([-0.1020, -0.0657, -0.3294, -0.0616, -0.0091])\n","A cat sits on the mat\n","Words: ['a', 'cat', 's', 'its', 'on', 'the', 'mat']\n","Word embeddings shape: torch.Size([7, 768])\n","Word: a, Embedding[:5]: tensor([-0.1559, -0.0341, -0.2607, -0.0940,  0.0162])\n","Word: cat, Embedding[:5]: tensor([-0.0803,  0.0340, -0.4989,  0.0117,  0.0195])\n","Word: s, Embedding[:5]: tensor([-0.1808,  0.0248, -0.3969,  0.0114,  0.1189])\n","Word: its, Embedding[:5]: tensor([-0.2043,  0.0310, -0.2345,  0.0119, -0.0082])\n","Word: on, Embedding[:5]: tensor([-0.1098, -0.0121, -0.3459,  0.0156,  0.0042])\n","Word: the, Embedding[:5]: tensor([-0.1116, -0.0376, -0.2625,  0.0089, -0.0062])\n","Word: mat, Embedding[:5]: tensor([-0.0722,  0.0115, -0.1853,  0.0544,  0.0918])\n","Sunny hills bloom with vivid colors\n","Words: ['s', 'unny', 'h', 'ills', 'bl', 'oom', 'with', 'v', 'ivid', 'col', 'ors']\n","Word embeddings shape: torch.Size([11, 768])\n","Word: s, Embedding[:5]: tensor([-0.1808,  0.0248, -0.3969,  0.0114,  0.1189])\n","Word: unny, Embedding[:5]: tensor([-0.0874,  0.0740, -0.3175, -0.1407, -0.1267])\n","Word: h, Embedding[:5]: tensor([-0.1616, -0.1259, -0.2825,  0.0080, -0.0340])\n","Word: ills, Embedding[:5]: tensor([-0.2217,  0.0008, -0.2705, -0.0416,  0.0089])\n","Word: bl, Embedding[:5]: tensor([-0.1034, -0.0911, -0.3072, -0.0716, -0.0238])\n","Word: oom, Embedding[:5]: tensor([-0.1916, -0.0918, -0.2759, -0.0024,  0.0361])\n","Word: with, Embedding[:5]: tensor([-0.0681, -0.0559, -0.4488, -0.0718,  0.0262])\n","Word: v, Embedding[:5]: tensor([-0.0803, -0.0413, -0.3704,  0.0569,  0.0110])\n","Word: ivid, Embedding[:5]: tensor([-0.0660, -0.1297, -0.4042, -0.0356,  0.0202])\n","Word: col, Embedding[:5]: tensor([-0.1892, -0.0240, -0.4099,  0.0079, -0.0550])\n","Word: ors, Embedding[:5]: tensor([-0.1780, -0.0210, -0.2533,  0.0236,  0.0135])\n"]}],"source":["import torch\n","from transformers import GPT2Tokenizer, GPT2Model\n","from typing import List, Tuple\n","import nltk\n","from nltk.tokenize import word_tokenize\n","\n","# Download NLTK data\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","\n","# Initialize tokenizer and model\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token = tokenizer.eos_token\n","model = GPT2Model.from_pretrained('gpt2')\n","model.eval()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","def sentences_to_gpt2_embeddings(sentences: List[str]) -> torch.Tensor:\n","    inputs = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)\n","    inputs = {key: val.to(device) for key, val in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        last_hidden_states = outputs.last_hidden_state\n","\n","\n","    attention_mask = inputs['attention_mask']\n","    masked_hidden = last_hidden_states * attention_mask.unsqueeze(-1)\n","    embeddings = masked_hidden.sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)\n","\n","    return embeddings\n","\n","def to_vocab_words_and_vectors(sentences: List[str]) -> List[Tuple[List[str], torch.Tensor]]:\n","    results = []\n","\n","    for sentence in sentences:\n","        words = word_tokenize(sentence.lower())\n","\n","        tokens = []\n","        for word in words:\n","            token_ids = tokenizer.encode(word, add_special_tokens=False)\n","            tokens.extend([tokenizer.decode([tid]) for tid in token_ids])\n","\n","        if not tokens:\n","            results.append(([], torch.tensor([])))\n","            continue\n","\n","        inputs = tokenizer(tokens, return_tensors='pt', padding=True,\n","                         truncation=True, is_split_into_words=False)\n","        inputs = {key: val.to(device) for key, val in inputs.items()}\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            embeddings = outputs.last_hidden_state\n","\n","        attention_mask = inputs['attention_mask']\n","        valid_embeddings = embeddings[attention_mask.bool()]\n","\n","        results.append((tokens, valid_embeddings))\n","\n","    return results\n","\n","\n","sentences = [\n","    \"The quick brown fox jumps over the lazy dog\",\n","    \"A cat sits on the mat\",\n","    \"Sunny hills bloom with vivid colors\"\n","]\n","\n","sentence_embeddings = sentences_to_gpt2_embeddings(sentences)\n","print(f\"Sentence embeddings shape: {sentence_embeddings.shape}\")\n","for i, (sentence, embedding) in enumerate(zip(sentences, sentence_embeddings)):\n","    print(f\"{sentence}\")\n","    print(f\"Embedding: {embedding[:5]}...\")\n","\n","word_results = to_vocab_words_and_vectors(sentences)\n","for i, (sentence, (words, word_embeddings)) in enumerate(zip(sentences, word_results)):\n","    print(f\"{sentence}\")\n","    print(f\"Words: {words}\")\n","    print(f\"Word embeddings shape: {word_embeddings.shape}\")\n","    for word, emb in zip(words, word_embeddings):\n","        print(f\"Word: {word}, Embedding[:5]: {emb[:5]}\")"]}]}